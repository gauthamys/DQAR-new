{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9arit379zEcC",
        "outputId": "4a0423d3-6f7e-4fb2-ba23-9a31644645f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DQAR'...\n",
            "remote: Enumerating objects: 305, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 305 (delta 1), reused 11 (delta 1), pack-reused 287 (from 1)\u001b[K\n",
            "Receiving objects: 100% (305/305), 41.44 MiB | 14.13 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gauthamys/DQAR-new.git DQAR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DQAR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f-B3IA1zxBA",
        "outputId": "6ce3d2ab-8641-4b0a-c631-65933d79c9c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DQAR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision diffusers accelerate tqdm"
      ],
      "metadata": {
        "id": "_bmt_D4pzyz_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/run_ablations.py \\\n",
        "    --main-only \\\n",
        "    --num-samples 8 \\\n",
        "    --save-images \\\n",
        "    --output-dir results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhHonyw2z2Gh",
        "outputId": "61d27092-b062-4e5b-dc02-24436312c74a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQAR Ablation Study\n",
            "==================\n",
            "Device: cuda\n",
            "Model: facebook/DiT-XL-2-256\n",
            "Samples per ablation: 8\n",
            "Default steps: 50\n",
            "Seed: 42\n",
            "Output: results/NVIDIA_A100-SXM4-40GB\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 03:23:10.893118: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 03:23:10.910694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764645790.932569    6665 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764645790.939137    6665 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764645790.955773    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645790.955813    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645790.955816    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645790.955819    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 03:23:10.960699: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.39it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.42it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded: facebook/DiT-XL-2-256\n",
            "\n",
            "Will run 4 ablations:\n",
            "  - baseline\n",
            "  - scheduling_only\n",
            "  - quant_cache_only\n",
            "  - full_dqar\n",
            "\n",
            "\n",
            "============================================================\n",
            "Running: baseline\n",
            "Description: No DQAR (baseline)\n",
            "DQAR: disabled\n",
            "============================================================\n",
            "DDIM Sampling: 100% 50/50 [00:02<00:00, 19.82it/s]\n",
            "Decoding and saving images...\n",
            "\n",
            "Results for baseline:\n",
            "  Total time: 2.53s\n",
            "  Time/sample: 0.317s\n",
            "  Speedup: 1.00x\n",
            "  Reuse ratio: 0.0%\n",
            "  Cache memory: 0.00 MB\n",
            "\n",
            "============================================================\n",
            "Running: scheduling_only\n",
            "Description: Layer scheduling only (FP16 cache)\n",
            "DQAR: enabled\n",
            "  - Quantization: 16-bit\n",
            "  - Layer scheduling: True\n",
            "  - Schedule type: linear\n",
            "============================================================\n",
            "[DQAR] Installed 28 attention processors\n",
            "DDIM Sampling: 100% 50/50 [00:02<00:00, 18.47it/s]\n",
            "Decoding and saving images...\n",
            "\n",
            "Results for scheduling_only:\n",
            "  Total time: 2.71s\n",
            "  Time/sample: 0.339s\n",
            "  Speedup: 0.94x\n",
            "  Reuse ratio: 8.8%\n",
            "  Cache memory: 504.00 MB\n",
            "\n",
            "============================================================\n",
            "Running: quant_cache_only\n",
            "Description: INT8 quantized cache (all layers)\n",
            "DQAR: enabled\n",
            "  - Quantization: 8-bit\n",
            "  - Layer scheduling: False\n",
            "  - Schedule type: linear\n",
            "============================================================\n",
            "[DQAR] Installed 28 attention processors\n",
            "DDIM Sampling: 100% 50/50 [00:01<00:00, 28.80it/s]\n",
            "Decoding and saving images...\n",
            "\n",
            "Results for quant_cache_only:\n",
            "  Total time: 1.74s\n",
            "  Time/sample: 0.217s\n",
            "  Speedup: 1.46x\n",
            "  Reuse ratio: 98.0%\n",
            "  Cache memory: 504.00 MB\n",
            "\n",
            "============================================================\n",
            "Running: full_dqar\n",
            "Description: Full DQAR (scheduling + INT8)\n",
            "DQAR: enabled\n",
            "  - Quantization: 8-bit\n",
            "  - Layer scheduling: True\n",
            "  - Schedule type: linear\n",
            "============================================================\n",
            "[DQAR] Installed 28 attention processors\n",
            "DDIM Sampling: 100% 50/50 [00:02<00:00, 18.57it/s]\n",
            "Decoding and saving images...\n",
            "\n",
            "Results for full_dqar:\n",
            "  Total time: 2.69s\n",
            "  Time/sample: 0.337s\n",
            "  Speedup: 0.94x\n",
            "  Reuse ratio: 8.8%\n",
            "  Cache memory: 504.00 MB\n",
            "\n",
            "============================================================\n",
            "Generating Report\n",
            "============================================================\n",
            "Report saved to: results/NVIDIA_A100-SXM4-40GB/ABLATION_REPORT.md\n",
            "Raw results saved to: results/NVIDIA_A100-SXM4-40GB/ablation_results.json\n",
            "\n",
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "\n",
            "Config                    Time/Sample  Speedup    Reuse %   \n",
            "------------------------------------------------------------\n",
            "baseline                  0.317s       1.00Ã—       0.0%\n",
            "scheduling_only           0.339s       0.94Ã—       8.8%\n",
            "quant_cache_only          0.217s       1.46Ã—       98.0%\n",
            "full_dqar                 0.337s       0.94Ã—       8.8%\n",
            "\n",
            "ðŸ† Best speedup: 1.46Ã— (quant_cache_only)\n",
            "ðŸ“Š Report: results/NVIDIA_A100-SXM4-40GB/ABLATION_REPORT.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/warmup_sweep.py --num-samples 4 --save-images --output-dir results/warmup_sweep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLCZCHUu_wzK",
        "outputId": "fa14f8b0-faa2-45a2-925b-a8a34d21fd7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQAR Warmup Sweep Benchmark\n",
            "==================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "Warmup rates: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
            "Max layers fraction: 0.33\n",
            "Samples per config: 4\n",
            "Output: results/warmup_sweep\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 03:14:08.358763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 03:14:08.376769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764645248.399314    4338 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764645248.406062    4338 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764645248.422948    4338 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645248.422987    4338 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645248.422990    4338 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645248.422993    4338 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 03:14:08.427877: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  8.80it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  5.18it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded: facebook/DiT-XL-2-256\n",
            "[DQAR] Installed 28 attention processors\n",
            "\n",
            "Running baseline...\n",
            "  Baseline: 2.74s/sample\n",
            "\n",
            "Running warmup sweep...\n",
            "\n",
            "Testing warmup=10%...\n",
            "  Time: 2.65s, Speedup: 1.03x, Reuse: 12.9%\n",
            "\n",
            "Testing warmup=20%...\n",
            "  Time: 2.63s, Speedup: 1.04x, Reuse: 11.6%\n",
            "\n",
            "Testing warmup=30%...\n",
            "  Time: 2.64s, Speedup: 1.04x, Reuse: 10.1%\n",
            "\n",
            "Testing warmup=40%...\n",
            "  Time: 2.62s, Speedup: 1.04x, Reuse: 8.8%\n",
            "\n",
            "Testing warmup=50%...\n",
            "  Time: 2.66s, Speedup: 1.03x, Reuse: 7.4%\n",
            "\n",
            "Testing warmup=60%...\n",
            "  Time: 2.69s, Speedup: 1.02x, Reuse: 6.0%\n",
            "\n",
            "Saved results to results/warmup_sweep/warmup_sweep_results.json\n",
            "\n",
            "Generating plots...\n",
            "  Saved plots to results/warmup_sweep/warmup_sweep_plots.png\n",
            "  Saved image grid to results/warmup_sweep/image_comparison.png\n",
            "\n",
            "Generating report...\n",
            "  Saved report to results/warmup_sweep/WARMUP_SWEEP_REPORT.md\n",
            "\n",
            "Done!\n",
            "Results saved to: results/warmup_sweep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DQAR/results/NVIDIA_A100-SXM4-40GB /content/DQAR/results/NVIDIA_A100-SXM4-40GB\n"
      ],
      "metadata": {
        "id": "SVA0Q7TW1lYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fe0761a4-79be-46e2-bf57-337d62a5c909"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/ablation_results.json (deflated 70%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/ABLATION_REPORT.md (deflated 49%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_005_class417.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_002_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_004_class88.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_007_class928.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_003_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_001_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/grid.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_000_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/quant_cache_only/sample_006_class279.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_005_class417.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_002_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_004_class88.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_007_class928.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_003_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_001_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/grid.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_000_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/full_dqar/sample_006_class279.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_005_class417.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_002_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_004_class88.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_007_class928.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_003_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_001_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/grid.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_000_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/baseline/sample_006_class279.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/ (stored 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_005_class417.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_002_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_004_class88.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_007_class928.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_003_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_001_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/grid.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_000_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/NVIDIA_A100-SXM4-40GB/images/scheduling_only/sample_006_class279.png (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DQAR/results/warmup_sweep /content/DQAR/results/warmup_sweep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKDGHEAS4hBN",
        "outputId": "973445cc-c358-4ea5-97e5-796c64508e29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DQAR/results/warmup_sweep/ (stored 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/warmup_sweep_plots.png (deflated 16%)\n",
            "  adding: content/DQAR/results/warmup_sweep/image_comparison.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/ (stored 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_60pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_50pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_10pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_40pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_10pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_40pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_30pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_30pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_50pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/baseline_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/baseline_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_20pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_60pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_30pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_50pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/baseline_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_50pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_40pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_20pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_10pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_30pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_20pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_10pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_20pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/baseline_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_60pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_60pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/images/warmup_40pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/warmup_sweep/warmup_sweep_results.json (deflated 81%)\n",
            "  adding: content/DQAR/results/warmup_sweep/warmup_sweep_plots.pdf (deflated 29%)\n",
            "  adding: content/DQAR/results/warmup_sweep/WARMUP_SWEEP_REPORT.md (deflated 49%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/layer_sweep.py --save-images --output-dir results/layer_sweep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzP0UpbnD_xu",
        "outputId": "57270a2f-60dc-409a-aa6e-f7ecaa13f56d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQAR Layer Fraction Sweep Benchmark\n",
            "==================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "Layer fractions: [0.33, 0.5, 0.66, 0.75, 1.0]\n",
            "Fixed warmup: 20%\n",
            "Samples per config: 4\n",
            "Output: results/layer_sweep\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 03:26:14.793280: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 03:26:14.811436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764645974.833445    7467 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764645974.840020    7467 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764645974.857275    7467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645974.857314    7467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645974.857317    7467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764645974.857321    7467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 03:26:14.862328: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.19it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  5.25it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded: facebook/DiT-XL-2-256\n",
            "[DQAR] Installed 28 attention processors\n",
            "\n",
            "Running baseline...\n",
            "  Baseline: 2.77s/sample\n",
            "\n",
            "Running layer fraction sweep...\n",
            "\n",
            "Testing layers=33%...\n",
            "  Time: 2.65s, Speedup: 1.04x, Reuse: 11.6%\n",
            "\n",
            "Testing layers=50%...\n",
            "  Time: 2.57s, Speedup: 1.08x, Reuse: 18.7%\n",
            "\n",
            "Testing layers=66%...\n",
            "  Time: 2.50s, Speedup: 1.11x, Reuse: 24.5%\n",
            "\n",
            "Testing layers=75%...\n",
            "  Time: 2.48s, Speedup: 1.12x, Reuse: 28.7%\n",
            "\n",
            "Testing layers=100%...\n",
            "  Time: 2.35s, Speedup: 1.18x, Reuse: 38.7%\n",
            "\n",
            "Saved results to results/layer_sweep/layer_sweep_results.json\n",
            "\n",
            "Generating plots...\n",
            "  Saved plots to results/layer_sweep/layer_sweep_plots.png\n",
            "  Saved image grid to results/layer_sweep/image_comparison.png\n",
            "\n",
            "Generating report...\n",
            "  Saved report to results/layer_sweep/LAYER_SWEEP_REPORT.md\n",
            "\n",
            "Done!\n",
            "Results saved to: results/layer_sweep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DQAR/results/layer_sweep /content/DQAR/results/layer_sweep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bak_xvZqGJNk",
        "outputId": "56f85f0d-6b40-4b14-b30d-e906a87cd3dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DQAR/results/layer_sweep/ (stored 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/layer_sweep_results.json (deflated 79%)\n",
            "  adding: content/DQAR/results/layer_sweep/image_comparison.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/LAYER_SWEEP_REPORT.md (deflated 51%)\n",
            "  adding: content/DQAR/results/layer_sweep/layer_sweep_plots.png (deflated 15%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/ (stored 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_33pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_33pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_100pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_100pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_100pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_66pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_33pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/baseline_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_100pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_50pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_50pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/baseline_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_75pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_50pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/baseline_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_75pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_66pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_75pct_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_75pct_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_50pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_66pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_66pct_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/layers_33pct_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/images/baseline_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep/layer_sweep_plots.pdf (deflated 29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --layer-fraction 0.99 --warmup-fraction 0.2 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQMt1qEeGqcZ",
        "outputId": "ee1d75ea-1ba7-41e1-ad89-ecf0c80ed321"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA L4\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  99%\n",
            "  Warmup Fraction: 20%\n",
            "  Schedule Mode:   normal (shallow layers)\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 06:26:13.954901: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 06:26:13.972546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764656773.994154   17157 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764656774.000633   17157 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764656774.017324   17157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764656774.017354   17157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764656774.017357   17157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764656774.017360   17157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 06:26:14.022258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:01,  1.17it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.08it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.76s/sample\n",
            "\n",
            "Running DQAR (layers=99%, warmup=20%)...\n",
            "  DQAR: 2.38s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.76s        2.38s       -0.38s\n",
            "Speedup                     1.00x        1.16x      +15.9%\n",
            "Reuse Ratio                    0%        37.4%      +37.4%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) achieved with 1.16x speedup\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --layer-fraction 0.66 --warmup-fraction 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKX9OlOiJYUz",
        "outputId": "91813737-67a4-4d0e-f334-6e674869d758"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  66%\n",
            "  Warmup Fraction: 20%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 03:41:29.266196: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 03:41:29.284001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764646889.305929   11344 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764646889.312524   11344 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764646889.329317   11344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764646889.329361   11344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764646889.329365   11344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764646889.329370   11344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 03:41:29.334347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.36it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.37it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.79s/sample\n",
            "\n",
            "Running DQAR (layers=66%, warmup=20%)...\n",
            "  DQAR: 2.54s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.79s        2.54s       -0.25s\n",
            "Speedup                     1.00x        1.10x       +9.9%\n",
            "Reuse Ratio                    0%        24.5%      +24.5%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.10x\n",
            "  Tip: Try increasing --layer-fraction (currently 66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --layer-fraction 0.0 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojevBH1DJomB",
        "outputId": "3e63feeb-0f5a-48da-862e-89cc333928d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  0%\n",
            "  Warmup Fraction: 20%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 04:51:30.032613: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 04:51:30.050256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764651090.071587   28482 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764651090.078164   28482 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764651090.094669   28482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651090.094696   28482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651090.094699   28482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651090.094702   28482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 04:51:30.099623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:01,  1.35it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.52it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.67s/sample\n",
            "\n",
            "Running DQAR (layers=0%, warmup=20%)...\n",
            "  DQAR: 2.66s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.67s        2.66s       -0.02s\n",
            "Speedup                     1.00x        1.01x       +0.6%\n",
            "Reuse Ratio                    0%         0.0%       +0.0%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.01x\n",
            "  Tip: Try increasing --layer-fraction (currently 0%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Al797TZqQ9",
        "outputId": "6b05a682-0122-4641-c312-6998369e8b56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 20%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 04:53:25.184835: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 04:53:25.202404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764651205.223502   29018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764651205.230019   29018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764651205.246409   29018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651205.246433   29018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651205.246436   29018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651205.246439   29018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 04:53:25.251281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  67% 2/3 [00:00<00:00,  4.92it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.53it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.66s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=20%)...\n",
            "  DQAR: 2.53s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.66s        2.53s       -0.12s\n",
            "Speedup                     1.00x        1.05x       +4.9%\n",
            "Reuse Ratio                    0%        11.6%      +11.6%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.05x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --layer-fraction 0.50 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w73Hbr8yaGYK",
        "outputId": "f496355f-5519-4d8e-de6c-26aa84fac73b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  50%\n",
            "  Warmup Fraction: 20%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 04:56:27.422457: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 04:56:27.442577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764651387.464513   29828 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764651387.471196   29828 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764651387.487827   29828 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651387.487852   29828 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651387.487855   29828 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651387.487859   29828 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 04:56:27.492730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:01,  1.34it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.48it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.63s/sample\n",
            "\n",
            "Running DQAR (layers=50%, warmup=20%)...\n",
            "  DQAR: 2.46s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.63s        2.46s       -0.17s\n",
            "Speedup                     1.00x        1.07x       +7.1%\n",
            "Reuse Ratio                    0%        18.7%      +18.7%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.07x\n",
            "  Tip: Try increasing --layer-fraction (currently 50%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!python scripts/benchmark_config.py --layer-fraction 1 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT6xE355ay4U",
        "outputId": "262666a9-e4aa-4bc9-dc1b-ec0619b22e68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '============================================================',\n",
              " 'DQAR BENCHMARK',\n",
              " '============================================================',\n",
              " 'Device: NVIDIA A100-SXM4-40GB',\n",
              " '',\n",
              " 'Configuration:',\n",
              " '  Layer Fraction:  100%',\n",
              " '  Warmup Fraction: 20%',\n",
              " '  Num Steps:       50',\n",
              " '  Num Samples:     4',\n",
              " '',\n",
              " 'Loading model...',\n",
              " '2025-12-02 04:58:19.528532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.',\n",
              " '2025-12-02 04:58:19.545985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered',\n",
              " 'WARNING: All log messages before absl::InitializeLog() is called are written to STDERR',\n",
              " 'E0000 00:00:1764651499.567086   30346 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered',\n",
              " 'E0000 00:00:1764651499.573618   30346 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered',\n",
              " 'W0000 00:00:1764651499.589867   30346 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.',\n",
              " 'W0000 00:00:1764651499.589893   30346 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.',\n",
              " 'W0000 00:00:1764651499.589897   30346 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.',\n",
              " 'W0000 00:00:1764651499.589901   30346 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.',\n",
              " '2025-12-02 04:58:19.594743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.',\n",
              " 'To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.',\n",
              " '',\n",
              " 'Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.',\n",
              " 'Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.',\n",
              " '',\n",
              " 'Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.54it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.',\n",
              " 'Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.',\n",
              " '',\n",
              " 'Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.48it/s]',\n",
              " 'Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.36it/s]',\n",
              " \"Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\",\n",
              " 'Model: facebook/DiT-XL-2-256',\n",
              " '',\n",
              " '[DQAR] Installed 28 attention processors',\n",
              " 'Running baseline (DQAR disabled)...',\n",
              " '',\n",
              " '  baseline:   0% 0/4 [00:00<?, ?it/s]',\n",
              " '  baseline:  25% 1/4 [00:02<00:08,  2.82s/it]',\n",
              " '  baseline:  50% 2/4 [00:05<00:05,  2.74s/it]',\n",
              " '  baseline:  75% 3/4 [00:08<00:02,  2.72s/it]',\n",
              " '  baseline: 100% 4/4 [00:10<00:00,  2.71s/it]',\n",
              " '                                             ',\n",
              " '  Baseline: 2.65s/sample',\n",
              " '',\n",
              " 'Running DQAR (layers=100%, warmup=20%)...',\n",
              " '',\n",
              " '  dqar:   0% 0/4 [00:00<?, ?it/s]',\n",
              " '  dqar:  25% 1/4 [00:02<00:07,  2.34s/it]',\n",
              " '  dqar:  50% 2/4 [00:04<00:04,  2.33s/it]',\n",
              " '  dqar:  75% 3/4 [00:07<00:02,  2.34s/it]',\n",
              " '  dqar: 100% 4/4 [00:09<00:00,  2.33s/it]',\n",
              " '                                         ',\n",
              " '  DQAR: 2.29s/sample',\n",
              " '',\n",
              " '============================================================',\n",
              " 'RESULTS',\n",
              " '============================================================',\n",
              " '',\n",
              " 'Metric                   Baseline         DQAR        Delta',\n",
              " '------------------------------------------------------------',\n",
              " 'Time/Sample                 2.65s        2.29s       -0.36s',\n",
              " 'Speedup                     1.00x        1.16x      +15.9%',\n",
              " 'Reuse Ratio                    0%        38.7%      +38.7%',\n",
              " 'Peak Memory                1869MB       1869MB         +0MB',\n",
              " 'Cache Memory                  0MB       63.0MB      +63.0MB',\n",
              " '------------------------------------------------------------',\n",
              " '',\n",
              " 'Target (1.15x) achieved with 1.16x speedup',\n",
              " 'Images saved to: results/benchmark']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --warmup-fraction 0 --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c-F81JabOP_",
        "outputId": "00a9726a-d553-46fb-9b4d-78beaf095123"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 0%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 05:02:41.548091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 05:02:41.565796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764651761.587233   31482 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764651761.593862   31482 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764651761.610338   31482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651761.610365   31482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651761.610370   31482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764651761.610374   31482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 05:02:41.615249: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.47it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.47it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.75s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=0%)...\n",
            "  DQAR: 2.58s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.75s        2.58s       -0.17s\n",
            "Speedup                     1.00x        1.07x       +6.6%\n",
            "Reuse Ratio                    0%        14.4%      +14.4%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.07x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --warmup-fraction 0.5 --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXJyKDJqcONx",
        "outputId": "f7a504b3-24a0-4a5e-c129-7b8794f801d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 50%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 05:08:24.055509: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 05:08:24.073090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764652104.094267   32934 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764652104.100825   32934 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764652104.117239   32934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652104.117269   32934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652104.117272   32934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652104.117275   32934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 05:08:24.122155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  67% 2/3 [00:00<00:00,  4.92it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.49it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.64s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=50%)...\n",
            "  DQAR: 2.59s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.64s        2.59s       -0.06s\n",
            "Speedup                     1.00x        1.02x       +2.1%\n",
            "Reuse Ratio                    0%         7.4%       +7.4%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.02x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "  Tip: Try decreasing --warmup-fraction (currently 50%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --warmup-fraction 0.75 --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55VwimrTdh2B",
        "outputId": "33dd5ff8-af50-4822-fdbe-dcd395ab63e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 75%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 05:09:46.433545: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 05:09:46.452166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764652186.473649   33324 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764652186.480249   33324 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764652186.496839   33324 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652186.496872   33324 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652186.496875   33324 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652186.496878   33324 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 05:09:46.501763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.46it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.26it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.69s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=75%)...\n",
            "  DQAR: 2.65s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.69s        2.65s       -0.04s\n",
            "Speedup                     1.00x        1.02x       +1.6%\n",
            "Reuse Ratio                    0%         3.9%       +3.9%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.02x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "  Tip: Try decreasing --warmup-fraction (currently 75%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --warmup-fraction 0.9 --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0_DecgPd181",
        "outputId": "235c63c6-77fb-4675-d7fa-c252e0b6d0d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 90%\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 05:12:25.845496: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 05:12:25.862763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764652345.884105   34086 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764652345.890558   34086 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764652345.907127   34086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652345.907167   34086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652345.907170   34086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652345.907174   34086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 05:12:25.912054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  2.54it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.48it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.67s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=90%)...\n",
            "  DQAR: 2.66s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.67s        2.66s       -0.00s\n",
            "Speedup                     1.00x        1.00x       +0.1%\n",
            "Reuse Ratio                    0%         1.8%       +1.8%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.00x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "  Tip: Try decreasing --warmup-fraction (currently 90%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/layer_sweep.py --reverse --output-dir results/layer_sweep_reverse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15SrKwk9eMh0",
        "outputId": "bfa86902-cd6f-480f-e396-090da3c64ea3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQAR Layer Fraction Sweep Benchmark\n",
            "==================================================\n",
            "Device: NVIDIA L4\n",
            "Layer fractions: [0.33, 0.5, 0.66, 0.75, 1.0]\n",
            "Fixed warmup: 20%\n",
            "Schedule mode: reverse (deep layers)\n",
            "Samples per config: 4\n",
            "Output: results/layer_sweep_reverse\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 05:20:46.632935: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 05:20:46.649064: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764652846.667634     779 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764652846.673058     779 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764652846.689307     779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652846.689351     779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652846.689354     779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764652846.689357     779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 05:20:46.694293: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model_index.json: 35.8kB [00:00, 74.3MB/s]\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]\n",
            "scheduler_config.json: 100% 310/310 [00:00<00:00, 3.00MB/s]\n",
            "\n",
            "config.json: 100% 602/602 [00:00<00:00, 4.77MB/s]\n",
            "Fetching 6 files:  33% 2/6 [00:00<00:00,  6.81it/s]\n",
            "config.json: 100% 601/601 [00:00<00:00, 6.06MB/s]\n",
            "\n",
            "transformer/diffusion_pytorch_model.bin:   0% 0.00/3.00G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "vae/diffusion_pytorch_model.bin:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "vae/diffusion_pytorch_model.bin:   0% 553k/335M [00:02<20:15, 275kB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae/diffusion_pytorch_model.bin:   8% 25.9M/335M [00:02<00:18, 16.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae/diffusion_pytorch_model.bin:  18% 61.5M/335M [00:02<00:06, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae/diffusion_pytorch_model.bin:  97% 325M/335M [00:02<00:00, 274MB/s]  \u001b[A\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:   2% 67.1M/3.00G [00:02<01:54, 25.7MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:   7% 201M/3.00G [00:03<00:39, 71.1MB/s] \u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  28% 842M/3.00G [00:03<00:05, 365MB/s] \u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  33% 987M/3.00G [00:03<00:04, 405MB/s]\u001b[A\n",
            "vae/diffusion_pytorch_model.bin: 100% 335M/335M [00:04<00:00, 72.6MB/s]\n",
            "\n",
            "transformer/diffusion_pytorch_model.bin:  43% 1.30G/3.00G [00:04<00:04, 376MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  46% 1.37G/3.00G [00:05<00:05, 309MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  50% 1.49G/3.00G [00:07<00:10, 142MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  66% 1.99G/3.00G [00:08<00:03, 270MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  71% 2.13G/3.00G [00:08<00:02, 304MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  80% 2.40G/3.00G [00:08<00:01, 432MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  84% 2.53G/3.00G [00:08<00:01, 393MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin:  89% 2.66G/3.00G [00:09<00:00, 456MB/s]\u001b[A\n",
            "transformer/diffusion_pytorch_model.bin: 100% 3.00G/3.00G [00:09<00:00, 321MB/s]\n",
            "Fetching 6 files: 100% 6/6 [00:09<00:00,  1.65s/it]\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  6.74it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.97it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded: facebook/DiT-XL-2-256\n",
            "[DQAR] Installed 28 attention processors\n",
            "\n",
            "Running baseline...\n",
            "  Baseline: 2.74s/sample\n",
            "\n",
            "Running layer fraction sweep...\n",
            "\n",
            "Testing layers=33%...\n",
            "  Time: 2.60s, Speedup: 1.05x, Reuse: 11.6%\n",
            "\n",
            "Testing layers=50%...\n",
            "  Time: 2.55s, Speedup: 1.08x, Reuse: 18.7%\n",
            "\n",
            "Testing layers=66%...\n",
            "  Time: 2.46s, Speedup: 1.11x, Reuse: 24.5%\n",
            "\n",
            "Testing layers=75%...\n",
            "  Time: 2.43s, Speedup: 1.13x, Reuse: 28.7%\n",
            "\n",
            "Testing layers=100%...\n",
            "  Time: 2.34s, Speedup: 1.17x, Reuse: 38.7%\n",
            "\n",
            "Saved results to results/layer_sweep_reverse/layer_sweep_results.json\n",
            "\n",
            "Generating plots...\n",
            "  Saved plots to results/layer_sweep_reverse/layer_sweep_plots.png\n",
            "  Saved image grid to results/layer_sweep_reverse/image_comparison.png\n",
            "\n",
            "Generating report...\n",
            "  Saved report to results/layer_sweep_reverse/LAYER_SWEEP_REPORT.md\n",
            "\n",
            "Done!\n",
            "Results saved to: results/layer_sweep_reverse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DQAR/results/layer_sweep_reverse /content/DQAR/results/layer_sweep_reverse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBRK-Su_gUk3",
        "outputId": "a62fb98f-f3ac-4534-fdfd-b0722191c56e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DQAR/results/layer_sweep_reverse/ (stored 0%)\n",
            "  adding: content/DQAR/results/layer_sweep_reverse/layer_sweep_results.json (deflated 79%)\n",
            "  adding: content/DQAR/results/layer_sweep_reverse/image_comparison.png (deflated 0%)\n",
            "  adding: content/DQAR/results/layer_sweep_reverse/LAYER_SWEEP_REPORT.md (deflated 51%)\n",
            "  adding: content/DQAR/results/layer_sweep_reverse/layer_sweep_plots.png (deflated 15%)\n",
            "  adding: content/DQAR/results/layer_sweep_reverse/layer_sweep_plots.pdf (deflated 29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch-fid"
      ],
      "metadata": {
        "id": "O35LUS_jyGke"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate_fid.py --layer-fraction 0.33 --warmup-fraction 0.2 --num-samples 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc0HcXHuhNzK",
        "outputId": "47110800-7a0c-4983-ad47-5d754fe21283"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FID EVALUATION: LINEAR vs LINEAR_REVERSE\n",
            "============================================================\n",
            "Device: NVIDIA L4\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 20%\n",
            "  Num Samples:     256\n",
            "  Num Steps:       50\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 06:38:42.130689: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 06:38:42.148268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764657522.169605   20325 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764657522.176192   20325 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764657522.192837   20325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764657522.192874   20325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764657522.192877   20325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764657522.192881   20325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 06:38:42.197859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  8.38it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  5.14it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded.\n",
            "\n",
            "Generating BASELINE images...\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Generating 256 images for baseline...\n",
            "  Saved to: results/fid_eval/baseline\n",
            "\n",
            "Generating LINEAR (shallow-first) images...\n",
            "  Generating 256 images for linear_shallow...\n",
            "  Saved to: results/fid_eval/linear_shallow\n",
            "\n",
            "Generating LINEAR_REVERSE (deep-first) images...\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Generating 256 images for linear_reverse_deep...\n",
            "  Saved to: results/fid_eval/linear_reverse_deep\n",
            "\n",
            "============================================================\n",
            "COMPUTING FID SCORES\n",
            "============================================================\n",
            "\n",
            "Computing FID: Baseline vs LINEAR (shallow-first)...\n",
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 388MB/s]\n",
            "100% 6/6 [00:01<00:00,  4.77it/s]\n",
            "100% 6/6 [00:01<00:00,  5.09it/s]\n",
            "  FID (Linear/Shallow): 16.25\n",
            "\n",
            "Computing FID: Baseline vs LINEAR_REVERSE (deep-first)...\n",
            "100% 6/6 [00:01<00:00,  5.14it/s]\n",
            "100% 6/6 [00:01<00:00,  5.07it/s]\n",
            "  FID (Reverse/Deep): 16.25\n",
            "\n",
            "Computing FID: LINEAR vs LINEAR_REVERSE...\n",
            "100% 6/6 [00:01<00:00,  5.09it/s]\n",
            "100% 6/6 [00:01<00:00,  5.07it/s]\n",
            "  FID (Linear vs Reverse): -0.00\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Configuration: 20% warmup, 33% layers\n",
            "Samples: 256\n",
            "\n",
            "Comparison                           FID Score\n",
            "--------------------------------------------------\n",
            "Baseline vs LINEAR (shallow)             16.25\n",
            "Baseline vs LINEAR_REVERSE (deep)        16.25\n",
            "LINEAR vs LINEAR_REVERSE                 -0.00\n",
            "--------------------------------------------------\n",
            "\n",
            "Better quality: Tie\n",
            "\n",
            "Results saved to: results/fid_eval/fid_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/tune_hyperparameters.py --num-samples 128 --output-dir results/tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoueAkjvyFAx",
        "outputId": "c751fe12-1fff-4df7-af99-15b8219c7549"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DQAR HYPERPARAMETER TUNING\n",
            "======================================================================\n",
            "Device: NVIDIA L4\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "Search Space:\n",
            "  Warmup values:  [0.1, 0.2, 0.3, 0.4]\n",
            "  Layer values:   [0.33, 0.5, 0.66, 0.75, 1.0]\n",
            "  Schedule types: ['linear', 'linear_reverse']\n",
            "  Total configs:  40\n",
            "\n",
            "Optimization:\n",
            "  Speedup weight: 0.50\n",
            "  FID weight:     0.50\n",
            "  Min speedup:    1.00x\n",
            "  Max FID:        50.0\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 07:15:08.339230: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 07:15:08.356633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764659708.378121   29724 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764659708.384632   29724 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764659708.401086   29724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764659708.401116   29724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764659708.401119   29724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764659708.401122   29724 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 07:15:08.406070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:00,  9.25it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  5.25it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded.\n",
            "\n",
            "======================================================================\n",
            "GENERATING BASELINE\n",
            "======================================================================\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Baseline time: 2.749s/sample\n",
            "  Saved to: results/tuning/images/baseline\n",
            "\n",
            "======================================================================\n",
            "HYPERPARAMETER SWEEP\n",
            "======================================================================\n",
            "\n",
            "[1/40] linear_w10_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.27it/s]\n",
            "100% 3/3 [00:00<00:00,  4.54it/s]\n",
            "  Speedup: 1.042x, FID: 23.02, Reuse: 0.0%\n",
            "[2/40] linear_reverse_w10_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.45it/s]\n",
            "100% 3/3 [00:00<00:00,  4.54it/s]\n",
            "  Speedup: 1.073x, FID: 23.02, Reuse: 0.0%\n",
            "[3/40] linear_w10_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.55it/s]\n",
            "100% 3/3 [00:00<00:00,  4.38it/s]\n",
            "  Speedup: 1.104x, FID: 34.17, Reuse: 0.0%\n",
            "[4/40] linear_reverse_w10_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.52it/s]\n",
            "100% 3/3 [00:00<00:00,  4.39it/s]\n",
            "  Speedup: 1.103x, FID: 34.17, Reuse: 0.0%\n",
            "[5/40] linear_w10_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.52it/s]\n",
            "100% 3/3 [00:00<00:00,  4.33it/s]\n",
            "  Speedup: 1.131x, FID: 41.64, Reuse: 0.0%\n",
            "[6/40] linear_reverse_w10_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.48it/s]\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "  Speedup: 1.133x, FID: 41.64, Reuse: 0.0%\n",
            "[7/40] linear_w10_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.47it/s]\n",
            "100% 3/3 [00:00<00:00,  4.33it/s]\n",
            "  Speedup: 1.152x, FID: 46.83, Reuse: 0.0%\n",
            "[8/40] linear_reverse_w10_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.47it/s]\n",
            "100% 3/3 [00:00<00:00,  4.27it/s]\n",
            "  Speedup: 1.154x, FID: 46.83, Reuse: 0.0%\n",
            "[9/40] linear_w10_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.45it/s]\n",
            "100% 3/3 [00:00<00:00,  4.28it/s]\n",
            "  Speedup: 1.211x, FID: 66.98, Reuse: 0.0%\n",
            "[10/40] linear_reverse_w10_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.45it/s]\n",
            "100% 3/3 [00:00<00:00,  4.32it/s]\n",
            "  Speedup: 1.207x, FID: 66.98, Reuse: 0.0%\n",
            "[11/40] linear_w20_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.43it/s]\n",
            "100% 3/3 [00:00<00:00,  4.37it/s]\n",
            "  Speedup: 1.063x, FID: 18.55, Reuse: 0.0%\n",
            "[12/40] linear_reverse_w20_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.41it/s]\n",
            "100% 3/3 [00:00<00:00,  4.38it/s]\n",
            "  Speedup: 1.062x, FID: 18.55, Reuse: 0.0%\n",
            "[13/40] linear_w20_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.42it/s]\n",
            "100% 3/3 [00:00<00:00,  4.31it/s]\n",
            "  Speedup: 1.088x, FID: 26.66, Reuse: 0.0%\n",
            "[14/40] linear_reverse_w20_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.42it/s]\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "  Speedup: 1.095x, FID: 26.66, Reuse: 0.0%\n",
            "[15/40] linear_w20_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.42it/s]\n",
            "100% 3/3 [00:00<00:00,  4.23it/s]\n",
            "  Speedup: 1.114x, FID: 34.14, Reuse: 0.0%\n",
            "[16/40] linear_reverse_w20_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.39it/s]\n",
            "100% 3/3 [00:00<00:00,  4.25it/s]\n",
            "  Speedup: 1.117x, FID: 34.14, Reuse: 0.0%\n",
            "[17/40] linear_w20_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.36it/s]\n",
            "100% 3/3 [00:00<00:00,  4.21it/s]\n",
            "  Speedup: 1.136x, FID: 38.47, Reuse: 0.0%\n",
            "[18/40] linear_reverse_w20_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "100% 3/3 [00:00<00:00,  4.21it/s]\n",
            "  Speedup: 1.134x, FID: 38.47, Reuse: 0.0%\n",
            "[19/40] linear_w20_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.35it/s]\n",
            "100% 3/3 [00:00<00:00,  4.22it/s]\n",
            "  Speedup: 1.182x, FID: 46.56, Reuse: 0.0%\n",
            "[20/40] linear_reverse_w20_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.33it/s]\n",
            "100% 3/3 [00:00<00:00,  4.22it/s]\n",
            "  Speedup: 1.184x, FID: 46.56, Reuse: 0.0%\n",
            "[21/40] linear_w30_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.23it/s]\n",
            "100% 3/3 [00:00<00:00,  4.30it/s]\n",
            "  Speedup: 1.056x, FID: 12.62, Reuse: 0.0%\n",
            "[22/40] linear_reverse_w30_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.35it/s]\n",
            "100% 3/3 [00:00<00:00,  4.27it/s]\n",
            "  Speedup: 1.054x, FID: 12.62, Reuse: 0.0%\n",
            "[23/40] linear_w30_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "100% 3/3 [00:00<00:00,  4.18it/s]\n",
            "  Speedup: 1.082x, FID: 21.07, Reuse: 0.0%\n",
            "[24/40] linear_reverse_w30_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "100% 3/3 [00:00<00:00,  4.23it/s]\n",
            "  Speedup: 1.081x, FID: 21.07, Reuse: 0.0%\n",
            "[25/40] linear_w30_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "100% 3/3 [00:00<00:00,  4.19it/s]\n",
            "  Speedup: 1.107x, FID: 26.16, Reuse: 0.0%\n",
            "[26/40] linear_reverse_w30_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.28it/s]\n",
            "100% 3/3 [00:00<00:00,  4.15it/s]\n",
            "  Speedup: 1.107x, FID: 26.16, Reuse: 0.0%\n",
            "[27/40] linear_w30_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.25it/s]\n",
            "100% 3/3 [00:00<00:00,  4.16it/s]\n",
            "  Speedup: 1.124x, FID: 28.72, Reuse: 0.0%\n",
            "[28/40] linear_reverse_w30_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.29it/s]\n",
            "100% 3/3 [00:00<00:00,  4.14it/s]\n",
            "  Speedup: 1.124x, FID: 28.72, Reuse: 0.0%\n",
            "[29/40] linear_w30_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.25it/s]\n",
            "100% 3/3 [00:00<00:00,  4.13it/s]\n",
            "  Speedup: 1.161x, FID: 37.01, Reuse: 0.0%\n",
            "[30/40] linear_reverse_w30_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.24it/s]\n",
            "100% 3/3 [00:00<00:00,  4.13it/s]\n",
            "  Speedup: 1.164x, FID: 37.01, Reuse: 0.0%\n",
            "[31/40] linear_w40_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.21it/s]\n",
            "100% 3/3 [00:00<00:00,  4.18it/s]\n",
            "  Speedup: 1.058x, FID: 8.32, Reuse: 0.0%\n",
            "[32/40] linear_reverse_w40_l33\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.24it/s]\n",
            "100% 3/3 [00:00<00:00,  4.20it/s]\n",
            "  Speedup: 1.056x, FID: 8.32, Reuse: 0.0%\n",
            "[33/40] linear_w40_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.19it/s]\n",
            "100% 3/3 [00:00<00:00,  4.12it/s]\n",
            "  Speedup: 1.076x, FID: 14.82, Reuse: 0.0%\n",
            "[34/40] linear_reverse_w40_l50\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.20it/s]\n",
            "100% 3/3 [00:00<00:00,  4.15it/s]\n",
            "  Speedup: 1.076x, FID: 14.82, Reuse: 0.0%\n",
            "[35/40] linear_w40_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.20it/s]\n",
            "100% 3/3 [00:00<00:00,  4.11it/s]\n",
            "  Speedup: 1.095x, FID: 18.82, Reuse: 0.0%\n",
            "[36/40] linear_reverse_w40_l66\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.21it/s]\n",
            "100% 3/3 [00:00<00:00,  4.11it/s]\n",
            "  Speedup: 1.094x, FID: 18.82, Reuse: 0.0%\n",
            "[37/40] linear_w40_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.17it/s]\n",
            "100% 3/3 [00:00<00:00,  4.08it/s]\n",
            "  Speedup: 1.111x, FID: 21.01, Reuse: 0.0%\n",
            "[38/40] linear_reverse_w40_l75\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.15it/s]\n",
            "100% 3/3 [00:00<00:00,  4.07it/s]\n",
            "  Speedup: 1.110x, FID: 21.01, Reuse: 0.0%\n",
            "[39/40] linear_w40_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.19it/s]\n",
            "100% 3/3 [00:00<00:00,  4.05it/s]\n",
            "  Speedup: 1.141x, FID: 26.24, Reuse: 0.0%\n",
            "[40/40] linear_reverse_w40_l100\n",
            "[DQAR] Installed 28 attention processors\n",
            "  Computing FID...\n",
            "100% 3/3 [00:00<00:00,  4.14it/s]\n",
            "100% 3/3 [00:00<00:00,  4.05it/s]\n",
            "  Speedup: 1.141x, FID: 26.24, Reuse: 0.0%\n",
            "\n",
            "======================================================================\n",
            "RESULTS\n",
            "======================================================================\n",
            "\n",
            "All Configurations (sorted by combined score):\n",
            "------------------------------------------------------------------------------------------\n",
            "Config                          Speedup      FID    Reuse    Score   Pareto\n",
            "------------------------------------------------------------------------------------------\n",
            "linear_w40_l33                   1.058x     8.32     0.0%    0.446       *âœ“\n",
            "linear_reverse_w40_l33           1.056x     8.32     0.0%    0.445        âœ“\n",
            "linear_w30_l33                   1.056x    12.62     0.0%    0.402       *âœ“\n",
            "linear_reverse_w30_l33           1.054x    12.62     0.0%    0.401        âœ“\n",
            "linear_w40_l50                   1.076x    14.82     0.0%    0.390       *âœ“\n",
            "linear_reverse_w40_l50           1.076x    14.82     0.0%    0.390        âœ“\n",
            "linear_w40_l66                   1.095x    18.82     0.0%    0.359       *âœ“\n",
            "linear_reverse_w40_l66           1.094x    18.82     0.0%    0.359        âœ“\n",
            "linear_w20_l33                   1.063x    18.55     0.0%    0.346       *âœ“\n",
            "linear_reverse_w20_l33           1.062x    18.55     0.0%    0.346        âœ“\n",
            "linear_w40_l75                   1.111x    21.01     0.0%    0.346       *âœ“\n",
            "linear_reverse_w40_l75           1.110x    21.01     0.0%    0.345        âœ“\n",
            "linear_w30_l50                   1.082x    21.07     0.0%    0.330       *âœ“\n",
            "linear_reverse_w30_l50           1.081x    21.07     0.0%    0.330        âœ“\n",
            "linear_reverse_w40_l100          1.141x    26.24     0.0%    0.308       *âœ“\n",
            "linear_w40_l100                  1.141x    26.24     0.0%    0.308       *âœ“\n",
            "linear_reverse_w10_l33           1.073x    23.02     0.0%    0.307       *âœ“\n",
            "linear_w30_l66                   1.107x    26.16     0.0%    0.292       *âœ“\n",
            "linear_reverse_w30_l66           1.107x    26.16     0.0%    0.292        âœ“\n",
            "linear_w10_l33                   1.042x    23.02     0.0%    0.291       *âœ“\n",
            "linear_reverse_w20_l50           1.095x    26.66     0.0%    0.281       *âœ“\n",
            "linear_w20_l50                   1.088x    26.66     0.0%    0.277       *âœ“\n",
            "linear_reverse_w30_l75           1.124x    28.72     0.0%    0.275       *âœ“\n",
            "linear_w30_l75                   1.124x    28.72     0.0%    0.275       *âœ“\n",
            "linear_reverse_w20_l66           1.117x    34.14     0.0%    0.217       *âœ“\n",
            "linear_w20_l66                   1.114x    34.14     0.0%    0.215       *âœ“\n",
            "linear_reverse_w30_l100          1.164x    37.01     0.0%    0.212       *âœ“\n",
            "linear_w30_l100                  1.161x    37.01     0.0%    0.210       *âœ“\n",
            "linear_w10_l50                   1.104x    34.17     0.0%    0.210       *âœ“\n",
            "linear_reverse_w10_l50           1.103x    34.17     0.0%    0.210        âœ“\n",
            "linear_w20_l75                   1.136x    38.47     0.0%    0.183       *âœ“\n",
            "linear_reverse_w20_l75           1.134x    38.47     0.0%    0.182        âœ“\n",
            "linear_reverse_w10_l66           1.133x    41.64     0.0%    0.150       *âœ“\n",
            "linear_w10_l66                   1.131x    41.64     0.0%    0.149       *âœ“\n",
            "linear_reverse_w20_l100          1.184x    46.56     0.0%    0.127       *âœ“\n",
            "linear_w20_l100                  1.182x    46.56     0.0%    0.125       *âœ“\n",
            "linear_reverse_w10_l75           1.154x    46.83     0.0%    0.109       *âœ“\n",
            "linear_w10_l75                   1.152x    46.83     0.0%    0.107       *âœ“\n",
            "linear_w10_l100                  1.211x    66.98     0.0%    0.105       *âœ—\n",
            "linear_reverse_w10_l100          1.207x    66.98     0.0%    0.103        âœ—\n",
            "------------------------------------------------------------------------------------------\n",
            "* = Pareto-optimal, âœ“ = meets constraints\n",
            "\n",
            "Pareto-Optimal Configurations:\n",
            "----------------------------------------------------------------------\n",
            "  linear_w40_l33: 1.058x speedup, 8.32 FID\n",
            "  linear_w40_l50: 1.076x speedup, 14.82 FID\n",
            "  linear_w40_l66: 1.095x speedup, 18.82 FID\n",
            "  linear_w40_l75: 1.111x speedup, 21.01 FID\n",
            "  linear_reverse_w40_l100: 1.141x speedup, 26.24 FID\n",
            "  linear_reverse_w30_l100: 1.164x speedup, 37.01 FID\n",
            "  linear_reverse_w20_l100: 1.184x speedup, 46.56 FID\n",
            "  linear_w10_l100: 1.211x speedup, 66.98 FID\n",
            "\n",
            "======================================================================\n",
            "LINEAR vs LINEAR_REVERSE COMPARISON\n",
            "======================================================================\n",
            "\n",
            "Warmup   Layers   Linear Speedup   Linear FID  Reverse Speedup  Reverse FID     Winner\n",
            "--------------------------------------------------------------------------------------------\n",
            "   10%     33%          1.042x        23.02           1.073x        23.02        Tie\n",
            "   10%     50%          1.104x        34.17           1.103x        34.17        Tie\n",
            "   10%     66%          1.131x        41.64           1.133x        41.64        Tie\n",
            "   10%     75%          1.152x        46.83           1.154x        46.83        Tie\n",
            "   10%    100%          1.211x        66.98           1.207x        66.98        Tie\n",
            "   20%     33%          1.063x        18.55           1.062x        18.55        Tie\n",
            "   20%     50%          1.088x        26.66           1.095x        26.66        Tie\n",
            "   20%     66%          1.114x        34.14           1.117x        34.14        Tie\n",
            "   20%     75%          1.136x        38.47           1.134x        38.47        Tie\n",
            "   20%    100%          1.182x        46.56           1.184x        46.56        Tie\n",
            "   30%     33%          1.056x        12.62           1.054x        12.62        Tie\n",
            "   30%     50%          1.082x        21.07           1.081x        21.07        Tie\n",
            "   30%     66%          1.107x        26.16           1.107x        26.16        Tie\n",
            "   30%     75%          1.124x        28.72           1.124x        28.72        Tie\n",
            "   30%    100%          1.161x        37.01           1.164x        37.01        Tie\n",
            "   40%     33%          1.058x         8.32           1.056x         8.32        Tie\n",
            "   40%     50%          1.076x        14.82           1.076x        14.82        Tie\n",
            "   40%     66%          1.095x        18.82           1.094x        18.82        Tie\n",
            "   40%     75%          1.111x        21.01           1.110x        21.01        Tie\n",
            "   40%    100%          1.141x        26.24           1.141x        26.24        Tie\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "Summary: Linear wins 0, Reverse wins 0, Ties 20\n",
            "\n",
            "Best LINEAR config (by FID): w40_l33 (1.058x, FID 8.32)\n",
            "Best REVERSE config (by FID): w40_l33 (1.056x, FID 8.32)\n",
            "\n",
            "======================================================================\n",
            "RECOMMENDED CONFIGURATION\n",
            "======================================================================\n",
            "\n",
            "  Schedule Type:    linear\n",
            "  Warmup Fraction:  40%\n",
            "  Layer Fraction:   33%\n",
            "\n",
            "  Speedup:          1.058x\n",
            "  FID Score:        8.32\n",
            "  Reuse Ratio:      0.0%\n",
            "  Combined Score:   0.446\n",
            "\n",
            "Configuration code:\n",
            "```python\n",
            "warmup_fraction = 0.4\n",
            "max_layers_fraction = 0.33\n",
            "schedule_type = \"linear\"\n",
            "```\n",
            "\n",
            "Results saved to: results/tuning/tuning_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/benchmark_config.py --warmup-fraction 0.4 --layer-fraction 0.33 --save-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR3FOG5P6iPW",
        "outputId": "1482f6ec-7f69-4bdd-ddde-0243f4fe0d11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DQAR BENCHMARK\n",
            "============================================================\n",
            "Device: NVIDIA L4\n",
            "\n",
            "Configuration:\n",
            "  Layer Fraction:  33%\n",
            "  Warmup Fraction: 40%\n",
            "  Schedule Mode:   normal (shallow layers)\n",
            "  Num Steps:       50\n",
            "  Num Samples:     4\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 11:13:35.710282: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 11:13:35.727699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764674015.748938   91343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764674015.756333   91343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764674015.773532   91343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764674015.773563   91343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764674015.773567   91343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764674015.773570   91343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 11:13:35.778474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  67% 2/3 [00:00<00:00,  2.57it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.40it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Running baseline (DQAR disabled)...\n",
            "  Baseline: 2.71s/sample\n",
            "\n",
            "Running DQAR (layers=33%, warmup=40%)...\n",
            "  DQAR: 2.63s/sample\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "\n",
            "Metric                   Baseline         DQAR        Delta\n",
            "------------------------------------------------------------\n",
            "Time/Sample                 2.71s        2.63s       -0.08s\n",
            "Speedup                     1.00x        1.03x       +3.1%\n",
            "Reuse Ratio                    0%         8.8%       +8.8%\n",
            "Peak Memory                1869MB       1869MB         +0MB\n",
            "Cache Memory                  0MB       63.0MB      +63.0MB\n",
            "------------------------------------------------------------\n",
            "\n",
            "Target (1.15x) not met. Current speedup: 1.03x\n",
            "  Tip: Try increasing --layer-fraction (currently 33%)\n",
            "  Tip: Try decreasing --warmup-fraction (currently 40%)\n",
            "Images saved to: results/benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DQAR/results/benchmark /content/DQAR/results/benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTgALEv0xHQX",
        "outputId": "862c573c-cf78-4928-ada3-c80ef15e71b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DQAR/results/benchmark/ (stored 0%)\n",
            "  adding: content/DQAR/results/benchmark/dqar_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/dqar_sample2_class387.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/baseline_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/baseline_sample3_class974.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/dqar_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/baseline_sample0_class207.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/dqar_sample1_class360.png (deflated 0%)\n",
            "  adding: content/DQAR/results/benchmark/baseline_sample2_class387.png (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/memory_profile.py --warmup-fraction 0.4 --layer-fraction 0.33 --output-dir results/memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKUMA_w5xoMI",
        "outputId": "8a003457-532d-4d57-d5bc-7f2cab203ba5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DQAR MEMORY PROFILER\n",
            "======================================================================\n",
            "Device: NVIDIA L4\n",
            "\n",
            "Configuration:\n",
            "  Warmup Fraction:  40%\n",
            "  Layer Fraction:   33%\n",
            "  Schedule Mode:    linear (shallow layers)\n",
            "  Num Steps:        50\n",
            "  Detailed Mode:    No\n",
            "\n",
            "Loading model...\n",
            "2025-12-02 11:32:27.966941: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 11:32:27.985363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764675148.007952   96195 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764675148.014678   96195 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764675148.031988   96195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764675148.032024   96195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764675148.032029   96195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764675148.032034   96195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 11:32:28.037130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading pipeline components...:   0% 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/transformer.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  33% 1/3 [00:00<00:01,  1.18it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--DiT-XL-2-256/snapshots/eab87f77abd5aef071a632f08807fbaab0b704d0/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 3/3 [00:00<00:00,  3.10it/s]\n",
            "Expected types for id2label: (typing.Dict[int, str], <class 'NoneType'>), got typing.Dict[str, str].\n",
            "Model loaded: facebook/DiT-XL-2-256\n",
            "\n",
            "[DQAR] Installed 28 attention processors\n",
            "Profiling baseline (no attention reuse)...\n",
            "  Peak memory: 1734.3 MB\n",
            "  Time: 3.08s\n",
            "\n",
            "Profiling DQAR (40% warmup, 33% layers)...\n",
            "  Peak memory: 1734.3 MB\n",
            "  Cache memory: 63.0 MB\n",
            "  Time: 2.67s\n",
            "\n",
            "======================================================================\n",
            "MEMORY PROFILE COMPARISON\n",
            "======================================================================\n",
            "\n",
            "Configuration: 40% warmup, 33% layers\n",
            "Inference steps: 50\n",
            "\n",
            "Metric                        Baseline         DQAR        Delta\n",
            "---------------------------------------------------------------\n",
            "Peak Allocated (MB)             1734.3       1734.3         +0.0\n",
            "Peak Reserved (MB)              1766.0       1766.0         +0.0\n",
            "Cache Memory (MB)                  0.0         63.0        +63.0\n",
            "Total Overhead (MB)                  -            -        +63.0\n",
            "---------------------------------------------------------------\n",
            "Inference Time (s)                3.08         2.67        -0.41\n",
            "Time per Step (ms)                61.6         53.3         -8.2\n",
            "Speedup                          1.00x        1.15x            -\n",
            "\n",
            "Memory Efficiency Analysis:\n",
            "----------------------------------------\n",
            "  Memory overhead: 63.0 MB (3.6% of baseline)\n",
            "  Cache utilization: 63.0 MB for attention outputs\n",
            "  Memory cost per 1% speedup: 4.09 MB\n",
            "\n",
            "Results saved to: results/memory/memory_profile_w40_l33.json\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJPLyDHazxVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}